{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime      Open      High       Low     Close    Volume  \\\n",
      "0 2021-01-01 00:00:00  0.250730  0.251106  0.250628  0.250493  0.076344   \n",
      "1 2021-01-01 01:00:00  0.251433  0.251695  0.251353  0.251520  0.015258   \n",
      "2 2021-01-01 02:00:00  0.256154  0.256011  0.255263  0.255877  0.034476   \n",
      "3 2021-01-01 03:00:00  0.252147  0.252928  0.252351  0.253123  0.010795   \n",
      "4 2021-01-01 04:00:00  0.254932  0.255284  0.254180  0.254066  0.023016   \n",
      "\n",
      "   sentiment_score  bert_sentiment  prev_close  prev_vader_sentiment  \\\n",
      "0              0.0             0.0    0.250493                   0.0   \n",
      "1              0.0             0.0    0.250493                   0.0   \n",
      "2              0.0             0.0    0.251520                   0.0   \n",
      "3              0.0             0.0    0.255877                   0.0   \n",
      "4              0.0             0.0    0.253123                   0.0   \n",
      "\n",
      "   prev_bert_sentiment  volatility_7d  volatility_14d  volatility_30d  \\\n",
      "0                  0.0       0.050683        0.068865        0.057312   \n",
      "1                  0.0       0.050683        0.068865        0.057312   \n",
      "2                  0.0       0.050683        0.068865        0.057312   \n",
      "3                  0.0       0.050683        0.068865        0.057312   \n",
      "4                  0.0       0.050683        0.068865        0.057312   \n",
      "\n",
      "   closing_7d_avg  closing_30d_avg  \n",
      "0        0.320975         0.357583  \n",
      "1        0.320975         0.357583  \n",
      "2        0.320975         0.357583  \n",
      "3        0.320975         0.357583  \n",
      "4        0.320975         0.357583  \n",
      "Index(['datetime', 'Open', 'High', 'Low', 'Close', 'Volume', 'sentiment_score',\n",
      "       'bert_sentiment', 'prev_close', 'prev_vader_sentiment',\n",
      "       'prev_bert_sentiment', 'volatility_7d', 'volatility_14d',\n",
      "       'volatility_30d', 'closing_7d_avg', 'closing_30d_avg'],\n",
      "      dtype='object')\n",
      "Total data points (hours): 18265\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Read the correct latest merged hourly dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "merged_data = pd.read_parquet('../datasets/final_merged_dataset_hourly.parquet')\n",
    "\n",
    "# Confirm the dataset is loaded\n",
    "print(merged_data.head())\n",
    "print(merged_data.columns)\n",
    "print(f\"Total data points (hours): {len(merged_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime      Open      High       Low     Close    Volume  \\\n",
      "0 2021-01-01 00:00:00  0.250730  0.251106  0.250628  0.250493  0.076344   \n",
      "1 2021-01-01 01:00:00  0.251433  0.251695  0.251353  0.251520  0.015258   \n",
      "2 2021-01-01 02:00:00  0.256154  0.256011  0.255263  0.255877  0.034476   \n",
      "3 2021-01-01 03:00:00  0.252147  0.252928  0.252351  0.253123  0.010795   \n",
      "4 2021-01-01 04:00:00  0.254932  0.255284  0.254180  0.254066  0.023016   \n",
      "\n",
      "   sentiment_score  bert_sentiment  prev_close  prev_vader_sentiment  \\\n",
      "0              0.0             0.0    0.250493                   0.0   \n",
      "1              0.0             0.0    0.250493                   0.0   \n",
      "2              0.0             0.0    0.251520                   0.0   \n",
      "3              0.0             0.0    0.255877                   0.0   \n",
      "4              0.0             0.0    0.253123                   0.0   \n",
      "\n",
      "   prev_bert_sentiment  volatility_7d  volatility_14d  volatility_30d  \\\n",
      "0                  0.0       0.050683        0.068865        0.057312   \n",
      "1                  0.0       0.050683        0.068865        0.057312   \n",
      "2                  0.0       0.050683        0.068865        0.057312   \n",
      "3                  0.0       0.050683        0.068865        0.057312   \n",
      "4                  0.0       0.050683        0.068865        0.057312   \n",
      "\n",
      "   closing_7d_avg  closing_30d_avg  \n",
      "0        0.320975         0.357583  \n",
      "1        0.320975         0.357583  \n",
      "2        0.320975         0.357583  \n",
      "3        0.320975         0.357583  \n",
      "4        0.320975         0.357583  \n",
      "Index(['datetime', 'Open', 'High', 'Low', 'Close', 'Volume', 'sentiment_score',\n",
      "       'bert_sentiment', 'prev_close', 'prev_vader_sentiment',\n",
      "       'prev_bert_sentiment', 'volatility_7d', 'volatility_14d',\n",
      "       'volatility_30d', 'closing_7d_avg', 'closing_30d_avg'],\n",
      "      dtype='object')\n",
      "Total data points (hours): 18265\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Read the correct latest merged hourly dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "merged_data = pd.read_parquet('../datasets/final_merged_dataset_hourly.parquet')\n",
    "\n",
    "# Confirm the dataset is loaded\n",
    "print(merged_data.head())\n",
    "print(merged_data.columns)\n",
    "print(f\"Total data points (hours): {len(merged_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "2021-01-01 00:00:00    0.250493\n",
      "2021-01-01 01:00:00    0.251520\n",
      "2021-01-01 02:00:00    0.255877\n",
      "2021-01-01 03:00:00    0.253123\n",
      "2021-01-01 04:00:00    0.254066\n",
      "Name: Close, dtype: float64\n",
      "Total hours of data: 18265\n"
     ]
    }
   ],
   "source": [
    "# Step 1 (updated): Set datetime as index\n",
    "merged_data['datetime'] = pd.to_datetime(merged_data['datetime'])  # Ensure proper datetime format\n",
    "merged_data = merged_data.set_index('datetime')\n",
    "\n",
    "# Now extract Close prices\n",
    "btc_close = merged_data['Close']\n",
    "\n",
    "# Sanity check\n",
    "print(btc_close.head())\n",
    "print(f\"Total hours of data: {len(btc_close)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.3083240084755148\n",
      "p-value: 0.6253555173021281\n",
      "Critical Value (1%): -3.4307086827260513\n",
      "Critical Value (5%): -2.861698524313042\n",
      "Critical Value (10%): -2.5668543783071662\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Step 2: Perform ADF Test on btc_close\n",
    "result = adfuller(btc_close)\n",
    "\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])\n",
    "for key, value in result[4].items():\n",
    "    print(f\"Critical Value ({key}): {value}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non stationary dataaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Differencing - ADF Statistic: -25.82320214571103\n",
      "After Differencing - p-value: 0.0\n",
      "Critical Value (1%): -3.4307086827260513\n",
      "Critical Value (5%): -2.861698524313042\n",
      "Critical Value (10%): -2.5668543783071662\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Apply first-order differencing\n",
    "btc_close_diff = btc_close.diff().dropna()\n",
    "\n",
    "# Re-run ADF test after differencing\n",
    "result_diff = adfuller(btc_close_diff)\n",
    "\n",
    "print(\"After Differencing - ADF Statistic:\", result_diff[0])\n",
    "print(\"After Differencing - p-value:\", result_diff[1])\n",
    "for key, value in result_diff[4].items():\n",
    "    print(f\"Critical Value ({key}): {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the data is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=-134303.582, Time=1.00 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=-134302.237, Time=0.86 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=-134302.256, Time=0.89 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=-134305.565, Time=0.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=-134302.048, Time=1.66 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
      "Total fit time: 4.754 seconds\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                18265\n",
      "Model:               SARIMAX(0, 1, 0)   Log Likelihood               67153.782\n",
      "Date:                Thu, 17 Apr 2025   AIC                        -134305.565\n",
      "Time:                        22:04:32   BIC                        -134297.752\n",
      "Sample:                    01-01-2021   HQIC                       -134302.997\n",
      "                         - 02-01-2023                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "sigma2      3.748e-05   1.33e-07    280.952      0.000    3.72e-05    3.77e-05\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.66   Jarque-Bera (JB):            177856.79\n",
      "Prob(Q):                              0.42   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.10   Skew:                            -0.14\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        18.29\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "import pmdarima as pm\n",
    "\n",
    "# Step 4: Auto ARIMA to find best p and q\n",
    "auto_model = pm.auto_arima(\n",
    "    btc_close,\n",
    "    start_p=0, start_q=0,\n",
    "    max_p=5, max_q=5,\n",
    "    d=1,\n",
    "    seasonal=False,\n",
    "    trace=True,\n",
    "    error_action='ignore',\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True\n",
    ")\n",
    "\n",
    "print(auto_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA(1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency h will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency h will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency h will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                  Close   No. Observations:                18265\n",
      "Model:                 ARIMA(0, 1, 0)   Log Likelihood               67153.782\n",
      "Date:                Thu, 17 Apr 2025   AIC                        -134305.565\n",
      "Time:                        22:05:39   BIC                        -134297.752\n",
      "Sample:                    01-01-2021   HQIC                       -134302.997\n",
      "                         - 02-01-2023                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "sigma2      3.748e-05   1.33e-07    280.952      0.000    3.72e-05    3.77e-05\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.66   Jarque-Bera (JB):            177856.79\n",
      "Prob(Q):                              0.42   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.10   Skew:                            -0.14\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        18.29\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Step 5: Train ARIMA(0,1,0)\n",
    "model = ARIMA(btc_close, order=(0,1,0))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model_fit.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-01 01:00:00    0.142479\n",
      "2023-02-01 02:00:00    0.142479\n",
      "2023-02-01 03:00:00    0.142479\n",
      "2023-02-01 04:00:00    0.142479\n",
      "2023-02-01 05:00:00    0.142479\n",
      "2023-02-01 06:00:00    0.142479\n",
      "2023-02-01 07:00:00    0.142479\n",
      "2023-02-01 08:00:00    0.142479\n",
      "2023-02-01 09:00:00    0.142479\n",
      "2023-02-01 10:00:00    0.142479\n",
      "2023-02-01 11:00:00    0.142479\n",
      "2023-02-01 12:00:00    0.142479\n",
      "2023-02-01 13:00:00    0.142479\n",
      "2023-02-01 14:00:00    0.142479\n",
      "2023-02-01 15:00:00    0.142479\n",
      "2023-02-01 16:00:00    0.142479\n",
      "2023-02-01 17:00:00    0.142479\n",
      "2023-02-01 18:00:00    0.142479\n",
      "2023-02-01 19:00:00    0.142479\n",
      "2023-02-01 20:00:00    0.142479\n",
      "2023-02-01 21:00:00    0.142479\n",
      "2023-02-01 22:00:00    0.142479\n",
      "2023-02-01 23:00:00    0.142479\n",
      "2023-02-02 00:00:00    0.142479\n",
      "2023-02-02 01:00:00    0.142479\n",
      "2023-02-02 02:00:00    0.142479\n",
      "2023-02-02 03:00:00    0.142479\n",
      "2023-02-02 04:00:00    0.142479\n",
      "2023-02-02 05:00:00    0.142479\n",
      "2023-02-02 06:00:00    0.142479\n",
      "Freq: h, Name: predicted_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Forecast next 30 steps (hours)\n",
    "n_forecast_steps = 30\n",
    "forecast = model_fit.forecast(steps=n_forecast_steps)\n",
    "\n",
    "# Display forecasted values\n",
    "print(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>bert_sentiment</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>prev_vader_sentiment</th>\n",
       "      <th>prev_bert_sentiment</th>\n",
       "      <th>volatility_7d</th>\n",
       "      <th>volatility_14d</th>\n",
       "      <th>volatility_30d</th>\n",
       "      <th>closing_7d_avg</th>\n",
       "      <th>closing_30d_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 00:00:00</th>\n",
       "      <td>0.250730</td>\n",
       "      <td>0.251106</td>\n",
       "      <td>0.250628</td>\n",
       "      <td>0.250493</td>\n",
       "      <td>0.076344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050683</td>\n",
       "      <td>0.068865</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.320975</td>\n",
       "      <td>0.357583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 01:00:00</th>\n",
       "      <td>0.251433</td>\n",
       "      <td>0.251695</td>\n",
       "      <td>0.251353</td>\n",
       "      <td>0.251520</td>\n",
       "      <td>0.015258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050683</td>\n",
       "      <td>0.068865</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.320975</td>\n",
       "      <td>0.357583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 02:00:00</th>\n",
       "      <td>0.256154</td>\n",
       "      <td>0.256011</td>\n",
       "      <td>0.255263</td>\n",
       "      <td>0.255877</td>\n",
       "      <td>0.034476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050683</td>\n",
       "      <td>0.068865</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.320975</td>\n",
       "      <td>0.357583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 03:00:00</th>\n",
       "      <td>0.252147</td>\n",
       "      <td>0.252928</td>\n",
       "      <td>0.252351</td>\n",
       "      <td>0.253123</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050683</td>\n",
       "      <td>0.068865</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.320975</td>\n",
       "      <td>0.357583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 04:00:00</th>\n",
       "      <td>0.254932</td>\n",
       "      <td>0.255284</td>\n",
       "      <td>0.254180</td>\n",
       "      <td>0.254066</td>\n",
       "      <td>0.023016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050683</td>\n",
       "      <td>0.068865</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.320975</td>\n",
       "      <td>0.357583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 20:00:00</th>\n",
       "      <td>0.141639</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.141621</td>\n",
       "      <td>0.141516</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005695</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>0.049219</td>\n",
       "      <td>0.140301</td>\n",
       "      <td>0.085659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 21:00:00</th>\n",
       "      <td>0.141620</td>\n",
       "      <td>0.141530</td>\n",
       "      <td>0.141734</td>\n",
       "      <td>0.141648</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.016183</td>\n",
       "      <td>0.049198</td>\n",
       "      <td>0.140323</td>\n",
       "      <td>0.085832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 22:00:00</th>\n",
       "      <td>0.141281</td>\n",
       "      <td>0.141285</td>\n",
       "      <td>0.141357</td>\n",
       "      <td>0.141403</td>\n",
       "      <td>0.006099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.016131</td>\n",
       "      <td>0.049175</td>\n",
       "      <td>0.140352</td>\n",
       "      <td>0.086004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 23:00:00</th>\n",
       "      <td>0.142167</td>\n",
       "      <td>0.142021</td>\n",
       "      <td>0.141961</td>\n",
       "      <td>0.141818</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.016084</td>\n",
       "      <td>0.049153</td>\n",
       "      <td>0.140378</td>\n",
       "      <td>0.086176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01 00:00:00</th>\n",
       "      <td>0.142412</td>\n",
       "      <td>0.142398</td>\n",
       "      <td>0.142433</td>\n",
       "      <td>0.142479</td>\n",
       "      <td>0.103838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.016049</td>\n",
       "      <td>0.049132</td>\n",
       "      <td>0.140398</td>\n",
       "      <td>0.086349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18265 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Open      High       Low     Close    Volume  \\\n",
       "datetime                                                                \n",
       "2021-01-01 00:00:00  0.250730  0.251106  0.250628  0.250493  0.076344   \n",
       "2021-01-01 01:00:00  0.251433  0.251695  0.251353  0.251520  0.015258   \n",
       "2021-01-01 02:00:00  0.256154  0.256011  0.255263  0.255877  0.034476   \n",
       "2021-01-01 03:00:00  0.252147  0.252928  0.252351  0.253123  0.010795   \n",
       "2021-01-01 04:00:00  0.254932  0.255284  0.254180  0.254066  0.023016   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2023-01-31 20:00:00  0.141639  0.141700  0.141621  0.141516  0.001596   \n",
       "2023-01-31 21:00:00  0.141620  0.141530  0.141734  0.141648  0.001272   \n",
       "2023-01-31 22:00:00  0.141281  0.141285  0.141357  0.141403  0.006099   \n",
       "2023-01-31 23:00:00  0.142167  0.142021  0.141961  0.141818  0.000531   \n",
       "2023-02-01 00:00:00  0.142412  0.142398  0.142433  0.142479  0.103838   \n",
       "\n",
       "                     sentiment_score  bert_sentiment  prev_close  \\\n",
       "datetime                                                           \n",
       "2021-01-01 00:00:00              0.0             0.0    0.250493   \n",
       "2021-01-01 01:00:00              0.0             0.0    0.250493   \n",
       "2021-01-01 02:00:00              0.0             0.0    0.251520   \n",
       "2021-01-01 03:00:00              0.0             0.0    0.255877   \n",
       "2021-01-01 04:00:00              0.0             0.0    0.253123   \n",
       "...                              ...             ...         ...   \n",
       "2023-01-31 20:00:00              0.0             0.0    0.141875   \n",
       "2023-01-31 21:00:00              0.0             0.0    0.141516   \n",
       "2023-01-31 22:00:00              0.0             0.0    0.141648   \n",
       "2023-01-31 23:00:00              0.0             0.0    0.141403   \n",
       "2023-02-01 00:00:00              0.0             0.0    0.141818   \n",
       "\n",
       "                     prev_vader_sentiment  prev_bert_sentiment  volatility_7d  \\\n",
       "datetime                                                                        \n",
       "2021-01-01 00:00:00                   0.0                  0.0       0.050683   \n",
       "2021-01-01 01:00:00                   0.0                  0.0       0.050683   \n",
       "2021-01-01 02:00:00                   0.0                  0.0       0.050683   \n",
       "2021-01-01 03:00:00                   0.0                  0.0       0.050683   \n",
       "2021-01-01 04:00:00                   0.0                  0.0       0.050683   \n",
       "...                                   ...                  ...            ...   \n",
       "2023-01-31 20:00:00                   0.0                  0.0       0.005695   \n",
       "2023-01-31 21:00:00                   0.0                  0.0       0.005692   \n",
       "2023-01-31 22:00:00                   0.0                  0.0       0.005685   \n",
       "2023-01-31 23:00:00                   0.0                  0.0       0.005682   \n",
       "2023-02-01 00:00:00                   0.0                  0.0       0.005684   \n",
       "\n",
       "                     volatility_14d  volatility_30d  closing_7d_avg  \\\n",
       "datetime                                                              \n",
       "2021-01-01 00:00:00        0.068865        0.057312        0.320975   \n",
       "2021-01-01 01:00:00        0.068865        0.057312        0.320975   \n",
       "2021-01-01 02:00:00        0.068865        0.057312        0.320975   \n",
       "2021-01-01 03:00:00        0.068865        0.057312        0.320975   \n",
       "2021-01-01 04:00:00        0.068865        0.057312        0.320975   \n",
       "...                             ...             ...             ...   \n",
       "2023-01-31 20:00:00        0.016235        0.049219        0.140301   \n",
       "2023-01-31 21:00:00        0.016183        0.049198        0.140323   \n",
       "2023-01-31 22:00:00        0.016131        0.049175        0.140352   \n",
       "2023-01-31 23:00:00        0.016084        0.049153        0.140378   \n",
       "2023-02-01 00:00:00        0.016049        0.049132        0.140398   \n",
       "\n",
       "                     closing_30d_avg  \n",
       "datetime                              \n",
       "2021-01-01 00:00:00         0.357583  \n",
       "2021-01-01 01:00:00         0.357583  \n",
       "2021-01-01 02:00:00         0.357583  \n",
       "2021-01-01 03:00:00         0.357583  \n",
       "2021-01-01 04:00:00         0.357583  \n",
       "...                              ...  \n",
       "2023-01-31 20:00:00         0.085659  \n",
       "2023-01-31 21:00:00         0.085832  \n",
       "2023-01-31 22:00:00         0.086004  \n",
       "2023-01-31 23:00:00         0.086176  \n",
       "2023-02-01 00:00:00         0.086349  \n",
       "\n",
       "[18265 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14013819 0.14430987 0.14242223 0.14247886 0.14076111 0.1416483\n",
      " 0.13464517 0.13353146 0.13417326 0.13404112 0.13607977 0.13602314\n",
      " 0.13607977 0.1364573  0.13611752 0.13651393 0.13485281 0.13577775\n",
      " 0.13872246 0.1374955  0.13713685 0.13579662 0.13674044 0.13753325\n",
      " 0.14187482 0.14151617 0.1416483  0.14140291 0.14181819 0.14247886]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Make sure the index is sorted (important)\n",
    "merged_data = merged_data.sort_index()\n",
    "\n",
    "# Step 2: Define number of steps\n",
    "n_forecast_steps = 30\n",
    "\n",
    "# Step 3: Find the last timestamp\n",
    "last_training_time = merged_data.index[-n_forecast_steps-1]\n",
    "\n",
    "# Step 4: Get actual Close values for next 30 hours\n",
    "actuals = merged_data[merged_data.index > last_training_time]['Close'].head(n_forecast_steps).values\n",
    "\n",
    "# Step 5: Display actual values\n",
    "print(actuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-01 01:00:00    0.142479\n",
      "2023-02-01 02:00:00    0.142479\n",
      "2023-02-01 03:00:00    0.142479\n",
      "2023-02-01 04:00:00    0.142479\n",
      "2023-02-01 05:00:00    0.142479\n",
      "2023-02-01 06:00:00    0.142479\n",
      "2023-02-01 07:00:00    0.142479\n",
      "2023-02-01 08:00:00    0.142479\n",
      "2023-02-01 09:00:00    0.142479\n",
      "2023-02-01 10:00:00    0.142479\n",
      "2023-02-01 11:00:00    0.142479\n",
      "2023-02-01 12:00:00    0.142479\n",
      "2023-02-01 13:00:00    0.142479\n",
      "2023-02-01 14:00:00    0.142479\n",
      "2023-02-01 15:00:00    0.142479\n",
      "2023-02-01 16:00:00    0.142479\n",
      "2023-02-01 17:00:00    0.142479\n",
      "2023-02-01 18:00:00    0.142479\n",
      "2023-02-01 19:00:00    0.142479\n",
      "2023-02-01 20:00:00    0.142479\n",
      "2023-02-01 21:00:00    0.142479\n",
      "2023-02-01 22:00:00    0.142479\n",
      "2023-02-01 23:00:00    0.142479\n",
      "2023-02-02 00:00:00    0.142479\n",
      "2023-02-02 01:00:00    0.142479\n",
      "2023-02-02 02:00:00    0.142479\n",
      "2023-02-02 03:00:00    0.142479\n",
      "2023-02-02 04:00:00    0.142479\n",
      "2023-02-02 05:00:00    0.142479\n",
      "2023-02-02 06:00:00    0.142479\n",
      "Freq: h, Name: predicted_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Forecast next 30 time steps using ARIMA model\n",
    "forecast = model_fit.forecast(steps=n_forecast_steps)\n",
    "\n",
    "# Display forecasted values\n",
    "print(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.005184\n",
      "MAPE: 3.13%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "# Step 5: Calculate RMSE and MAPE\n",
    "rmse = np.sqrt(mean_squared_error(actuals, forecast))\n",
    "mape = mean_absolute_percentage_error(actuals, forecast) * 100  # in percentage\n",
    "\n",
    "# Display Results\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from metric_logging import log_experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/17 23:46:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'ARIMA_model_for_hourly_data_Model'.\n",
      "2025/04/17 23:46:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ARIMA_model_for_hourly_data_Model, version 1\n",
      "Created version '1' of model 'ARIMA_model_for_hourly_data_Model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ARIMA_model_for_hourly_data registered and logged successfully to DagsHub MLflow.\n",
      "🏃 View run ARIMA_model_for_hourly_data-Baseline at: https://dagshub.com/vamsisaigarapati/bitcoin_price_pred_CSE574.mlflow/#/experiments/0/runs/9d373da8ab0c4013b47ee1efe7cb43eb\n",
      "🧪 View experiment at: https://dagshub.com/vamsisaigarapati/bitcoin_price_pred_CSE574.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"order\": \"(0, 1, 0)\",\n",
    "    \"seasonal_order\": \"(0, 0, 0, 0)\",  # No seasonal order for normal ARIMA\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAPE\": mape,\n",
    "}\n",
    "\n",
    "log_experiment(\"ARIMA_model_for_hourly_data\", model_object=model_fit, params=params, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency h will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/anaconda3/envs/bit_pred_env/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency h will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     SARIMAX Results                                      \n",
      "==========================================================================================\n",
      "Dep. Variable:                              Close   No. Observations:                18265\n",
      "Model:             SARIMAX(1, 1, 1)x(1, 1, 1, 24)   Log Likelihood               66919.304\n",
      "Date:                            Thu, 17 Apr 2025   AIC                        -133828.609\n",
      "Time:                                    23:48:00   BIC                        -133789.559\n",
      "Sample:                                01-01-2021   HQIC                       -133815.775\n",
      "                                     - 02-01-2023                                         \n",
      "Covariance Type:                              opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.0507      0.431      0.118      0.906      -0.794       0.895\n",
      "ma.L1         -0.0614      0.431     -0.143      0.887      -0.905       0.783\n",
      "ar.S.L24      -0.0395      0.005     -7.936      0.000      -0.049      -0.030\n",
      "ma.S.L24      -0.9986      0.004   -253.725      0.000      -1.006      -0.991\n",
      "sigma2      3.734e-05   1.92e-07    194.832      0.000     3.7e-05    3.77e-05\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.55   Jarque-Bera (JB):            168705.72\n",
      "Prob(Q):                              0.46   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.10   Skew:                            -0.17\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        17.91\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Step 1: Define SARIMA model order\n",
    "order = (1, 1, 1)\n",
    "seasonal_order = (1, 1, 1, 24)  # 24 hours seasonality (daily seasonality)\n",
    "\n",
    "# Step 2: Fit SARIMA model\n",
    "sarima_model = SARIMAX(\n",
    "    merged_data['Close'],\n",
    "    order=order,\n",
    "    seasonal_order=seasonal_order,\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "sarima_result = sarima_model.fit(disp=False)\n",
    "\n",
    "# Step 3: Summary of model\n",
    "print(sarima_result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-01 01:00:00    0.142523\n",
      "2023-02-01 02:00:00    0.143036\n",
      "2023-02-01 03:00:00    0.142825\n",
      "2023-02-01 04:00:00    0.142813\n",
      "2023-02-01 05:00:00    0.142790\n",
      "2023-02-01 06:00:00    0.142956\n",
      "2023-02-01 07:00:00    0.142683\n",
      "2023-02-01 08:00:00    0.142395\n",
      "2023-02-01 09:00:00    0.142450\n",
      "2023-02-01 10:00:00    0.142532\n",
      "2023-02-01 11:00:00    0.142470\n",
      "2023-02-01 12:00:00    0.142556\n",
      "2023-02-01 13:00:00    0.142520\n",
      "2023-02-01 14:00:00    0.142573\n",
      "2023-02-01 15:00:00    0.142502\n",
      "2023-02-01 16:00:00    0.142559\n",
      "2023-02-01 17:00:00    0.142425\n",
      "2023-02-01 18:00:00    0.142625\n",
      "2023-02-01 19:00:00    0.142386\n",
      "2023-02-01 20:00:00    0.142488\n",
      "2023-02-01 21:00:00    0.142263\n",
      "2023-02-01 22:00:00    0.142144\n",
      "2023-02-01 23:00:00    0.142217\n",
      "2023-02-02 00:00:00    0.142204\n",
      "2023-02-02 01:00:00    0.141977\n",
      "2023-02-02 02:00:00    0.142426\n",
      "2023-02-02 03:00:00    0.142249\n",
      "2023-02-02 04:00:00    0.142233\n",
      "2023-02-02 05:00:00    0.142290\n",
      "2023-02-02 06:00:00    0.142448\n",
      "Freq: h, Name: predicted_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define forecast horizon\n",
    "n_forecast_steps = 30\n",
    "\n",
    "# Forecast using SARIMA\n",
    "sarima_forecast = sarima_result.get_forecast(steps=n_forecast_steps)\n",
    "sarima_forecast_values = sarima_forecast.predicted_mean\n",
    "\n",
    "# Display the forecasted values\n",
    "print(sarima_forecast_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.005164\n",
      "MAPE: 3.11%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate RMSE and MAPE\n",
    "rmse = np.sqrt(mean_squared_error(actuals, sarima_forecast_values))\n",
    "mape = mean_absolute_percentage_error(actuals, sarima_forecast_values) * 100\n",
    "\n",
    "# Display\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/18 00:17:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'SARIMA_model_for_hourly_data_Model'.\n",
      "2025/04/18 00:35:22 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: SARIMA_model_for_hourly_data_Model, version 1\n",
      "Created version '1' of model 'SARIMA_model_for_hourly_data_Model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SARIMA_model_for_hourly_data registered and logged successfully to DagsHub MLflow.\n",
      "🏃 View run SARIMA_model_for_hourly_data-Baseline at: https://dagshub.com/vamsisaigarapati/bitcoin_price_pred_CSE574.mlflow/#/experiments/0/runs/781248fa6e1c46c3b19ecd690dc150f9\n",
      "🧪 View experiment at: https://dagshub.com/vamsisaigarapati/bitcoin_price_pred_CSE574.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Import the function\n",
    "# from src.metric_logging import log_experiment\n",
    "\n",
    "# Define parameters and metrics\n",
    "params = {\n",
    "    \"order\": \"(1, 1, 1)\",\n",
    "    \"seasonal_order\": \"(1, 1, 1, 24)\",  # SARIMA seasonal params\n",
    "    \"seasonality\": \"24 hours (daily seasonality)\"\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAPE\": mape\n",
    "}\n",
    "\n",
    "# Log experiment\n",
    "log_experiment(\"SARIMA_model_for_hourly_data\", model_object=sarima_result, params=params, metrics=metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bit_pred_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
