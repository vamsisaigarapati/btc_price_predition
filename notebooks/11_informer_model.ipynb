{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a08a562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Open      High       Low     Close    Volume  \\\n",
      "datetime                                                                \n",
      "2021-01-01 00:00:00  0.250730  0.251106  0.250628  0.250493  0.076344   \n",
      "2021-01-01 01:00:00  0.251433  0.251695  0.251353  0.251520  0.015258   \n",
      "2021-01-01 02:00:00  0.256154  0.256011  0.255263  0.255877  0.034476   \n",
      "2021-01-01 03:00:00  0.252147  0.252928  0.252351  0.253123  0.010795   \n",
      "2021-01-01 04:00:00  0.254932  0.255284  0.254180  0.254066  0.023016   \n",
      "\n",
      "                     sentiment_score  bert_sentiment  prev_close  \\\n",
      "datetime                                                           \n",
      "2021-01-01 00:00:00              0.0             0.0    0.250493   \n",
      "2021-01-01 01:00:00              0.0             0.0    0.250493   \n",
      "2021-01-01 02:00:00              0.0             0.0    0.251520   \n",
      "2021-01-01 03:00:00              0.0             0.0    0.255877   \n",
      "2021-01-01 04:00:00              0.0             0.0    0.253123   \n",
      "\n",
      "                     prev_vader_sentiment  prev_bert_sentiment  volatility_7d  \\\n",
      "datetime                                                                        \n",
      "2021-01-01 00:00:00                   0.0                  0.0       0.050683   \n",
      "2021-01-01 01:00:00                   0.0                  0.0       0.050683   \n",
      "2021-01-01 02:00:00                   0.0                  0.0       0.050683   \n",
      "2021-01-01 03:00:00                   0.0                  0.0       0.050683   \n",
      "2021-01-01 04:00:00                   0.0                  0.0       0.050683   \n",
      "\n",
      "                     volatility_14d  volatility_30d  closing_7d_avg  \\\n",
      "datetime                                                              \n",
      "2021-01-01 00:00:00        0.068865        0.057312        0.320975   \n",
      "2021-01-01 01:00:00        0.068865        0.057312        0.320975   \n",
      "2021-01-01 02:00:00        0.068865        0.057312        0.320975   \n",
      "2021-01-01 03:00:00        0.068865        0.057312        0.320975   \n",
      "2021-01-01 04:00:00        0.068865        0.057312        0.320975   \n",
      "\n",
      "                     closing_30d_avg  \n",
      "datetime                              \n",
      "2021-01-01 00:00:00         0.357583  \n",
      "2021-01-01 01:00:00         0.357583  \n",
      "2021-01-01 02:00:00         0.357583  \n",
      "2021-01-01 03:00:00         0.357583  \n",
      "2021-01-01 04:00:00         0.357583  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your final merged dataset\n",
    "merged_data = pd.read_parquet('../datasets/final_merged_dataset_hourly.parquet')\n",
    "\n",
    "# Sort by datetime if not already\n",
    "merged_data = merged_data.sort_values('datetime')\n",
    "merged_data.set_index('datetime', inplace=True)\n",
    "\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa199ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (18265, 7)\n",
      "Shape of y: (18265,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select features\n",
    "feature_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'sentiment_score', 'bert_sentiment']\n",
    "\n",
    "# Prepare input X and output y\n",
    "X = merged_data[feature_cols].values\n",
    "y = merged_data['Close'].values  # Target is 'Close' price\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f8b7b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_seq: (18241, 24, 7)\n",
      "Shape of y_seq: (18241, 1)\n"
     ]
    }
   ],
   "source": [
    "def create_sliding_windows(X, y, input_window=24, output_window=1):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - input_window - output_window + 1):\n",
    "        X_seq.append(X[i:i+input_window])\n",
    "        y_seq.append(y[i+input_window:i+input_window+output_window])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Create sequences\n",
    "input_window = 24    # 24 hours as input\n",
    "output_window = 1    # predict next 1 hour\n",
    "\n",
    "X_seq, y_seq = create_sliding_windows(X, y, input_window, output_window)\n",
    "\n",
    "print(f\"Shape of X_seq: {X_seq.shape}\")\n",
    "print(f\"Shape of y_seq: {y_seq.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6286e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 14592\n",
      "Testing samples: 3649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq, y_seq, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d903feb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'informer.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minformer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Informer\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Check if GPU is available\u001b[39;00m\n\u001b[32m      6\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'informer.models'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from informer.models.informer import Informer\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "enc_in = X_train.shape[2]  # number of features\n",
    "dec_in = X_train.shape[2]  # same input size\n",
    "c_out = 1                 # output size (predict Close price)\n",
    "seq_len = X_train.shape[1] # input sequence length (24)\n",
    "label_len = 12             # how many previous labels known to decoder\n",
    "out_len = 1                # predict next 1 hour\n",
    "d_model = 512              # hidden size\n",
    "n_heads = 8\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "dropout = 0.05\n",
    "factor = 5  # ProbSparse attention factor\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Define Informer model\n",
    "model = Informer(\n",
    "    enc_in=enc_in,\n",
    "    dec_in=dec_in,\n",
    "    c_out=c_out,\n",
    "    seq_len=seq_len,\n",
    "    label_len=label_len,\n",
    "    out_len=out_len,\n",
    "    d_model=d_model,\n",
    "    n_heads=n_heads,\n",
    "    e_layers=e_layers,\n",
    "    d_layers=d_layers,\n",
    "    dropout=dropout,\n",
    "    factor=factor,\n",
    "    device=device,\n",
    ").to(device)\n",
    "\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bit_pred_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
