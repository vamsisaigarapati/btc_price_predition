{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78662e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime      Open      High       Low     Close    Volume  \\\n",
      "0 2021-01-01 00:00:00  0.250730  0.251106  0.250628  0.250493  0.076344   \n",
      "1 2021-01-01 01:00:00  0.251433  0.251695  0.251353  0.251520  0.015258   \n",
      "2 2021-01-01 02:00:00  0.256154  0.256011  0.255263  0.255877  0.034476   \n",
      "3 2021-01-01 03:00:00  0.252147  0.252928  0.252351  0.253123  0.010795   \n",
      "4 2021-01-01 04:00:00  0.254932  0.255284  0.254180  0.254066  0.023016   \n",
      "\n",
      "   sentiment_score  bert_sentiment  prev_close  prev_vader_sentiment  \\\n",
      "0              0.0             0.0    0.250493                   0.0   \n",
      "1              0.0             0.0    0.250493                   0.0   \n",
      "2              0.0             0.0    0.251520                   0.0   \n",
      "3              0.0             0.0    0.255877                   0.0   \n",
      "4              0.0             0.0    0.253123                   0.0   \n",
      "\n",
      "   prev_bert_sentiment  volatility_7d  volatility_14d  volatility_30d  \\\n",
      "0                  0.0       0.050683        0.068865        0.057312   \n",
      "1                  0.0       0.050683        0.068865        0.057312   \n",
      "2                  0.0       0.050683        0.068865        0.057312   \n",
      "3                  0.0       0.050683        0.068865        0.057312   \n",
      "4                  0.0       0.050683        0.068865        0.057312   \n",
      "\n",
      "   closing_7d_avg  closing_30d_avg  \n",
      "0        0.320975         0.357583  \n",
      "1        0.320975         0.357583  \n",
      "2        0.320975         0.357583  \n",
      "3        0.320975         0.357583  \n",
      "4        0.320975         0.357583  \n",
      "Index(['datetime', 'Open', 'High', 'Low', 'Close', 'Volume', 'sentiment_score',\n",
      "       'bert_sentiment', 'prev_close', 'prev_vader_sentiment',\n",
      "       'prev_bert_sentiment', 'volatility_7d', 'volatility_14d',\n",
      "       'volatility_30d', 'closing_7d_avg', 'closing_30d_avg'],\n",
      "      dtype='object')\n",
      "Total data points (hours): 18265\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "merged_data = pd.read_parquet('../datasets/final_merged_dataset_hourly.parquet')\n",
    "\n",
    "# Confirm the dataset is loaded\n",
    "print(merged_data.head())\n",
    "print(merged_data.columns)\n",
    "print(f\"Total data points (hours): {len(merged_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0df63a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18264, 14) (18264,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "# Assume your hourly merged dataset is already loaded as `merged_data`\n",
    "\n",
    "# Step 1.1: Sort by datetime and set index if not already\n",
    "merged_data = merged_data.sort_index()\n",
    "\n",
    "# Step 1.2: Select Features and Target\n",
    "feature_cols = [\n",
    "    'Open', 'High', 'Low', 'Volume',\n",
    "    'sentiment_score', 'bert_sentiment',\n",
    "    'prev_close', 'prev_vader_sentiment', 'prev_bert_sentiment',\n",
    "    'volatility_7d', 'volatility_14d', 'volatility_30d',\n",
    "    'closing_7d_avg', 'closing_30d_avg'\n",
    "]\n",
    "target_col = 'Close'  # We are predicting the next hour's Close price\n",
    "\n",
    "# Step 1.3: Shift the target for next-hour prediction\n",
    "merged_data['target'] = merged_data['Close'].shift(-1)\n",
    "\n",
    "# Drop any final row with NaN after shifting\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "# Step 1.4: Prepare X and y\n",
    "X = merged_data[feature_cols]\n",
    "y = merged_data['target']\n",
    "\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca879c4",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.001976\n",
      "MAPE: 396081300931.24%\n"
     ]
    }
   ],
   "source": [
    "# Step 2.1: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# Step 2.2: Initialize and Train Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 2.3: Make Predictions\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Step 2.4: Evaluate the Model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) * 100  # in percentage\n",
    "\n",
    "# Step 2.5: Print Evaluation Metrics\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c7c29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe MAPE: 2.46%\n"
     ]
    }
   ],
   "source": [
    "# Safe MAPE calculation\n",
    "threshold = 0.01  # anything below 0.01 is too small\n",
    "mask = np.abs(y_test) > threshold\n",
    "\n",
    "MAPE = mean_absolute_percentage_error(y_test[mask], y_pred[mask]) * 100\n",
    "\n",
    "print(f\"Safe MAPE: {MAPE:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b33b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from metric_logging import log_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e161c149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019759597333663024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse\n",
    "MAPE\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b75e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare parameters and metrics\n",
    "params = {\n",
    "    \"model_type\": \"Linear Regression\",\n",
    "    \"features_used\": \"Lag features, Moving Averages, Volatility Indicators\",\n",
    "    \"test_size\": \"20%\",\n",
    "    \"shuffle\": \"False\"\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"RMSE\": rmse,\n",
    "    \"MAPE\": MAPE\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eb9b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Set up MLflow tracking URI and authentication for DagsHub\n",
    "MLFLOW_TRACKING_URI = \"https://dagshub.com/vamsisaigarapati/bitcoin_price_pred_CSE574.mlflow\"\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'vamsisaigarapati'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = '0d66986d30f48a915d60b73c435bdae6ee103eb8'\n",
    "\n",
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"Bitcoin_Price_Prediction_CSE574\")\n",
    "\n",
    "def log_experiment(model_name, params, metrics, model_object=None):\n",
    "    \"\"\"\n",
    "    Logs model, parameters, and evaluation metrics to MLflow (DagsHub).\n",
    "    Model logging is optional.\n",
    "    \n",
    "    :param model_name: (str) Name of the model (e.g., \"ARIMA\", \"XGBoost\", \"LSTM\").\n",
    "    :param params: (dict) Hyperparameters used for the model.\n",
    "    :param metrics: (dict) Performance metrics (e.g., RMSE, MAPE).\n",
    "    :param model_object: (optional) Trained model object to be saved (e.g., sklearn, SARIMA, etc.)\n",
    "    \"\"\"\n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "\n",
    "        # 1. Save the model only if provided\n",
    "        if model_object is not None:\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=model_object,\n",
    "                artifact_path=\"model\",\n",
    "                registered_model_name=f\"{model_name}_Model\"\n",
    "            )\n",
    "\n",
    "        # 2. Log parameters\n",
    "        for param_name, param_value in params.items():\n",
    "            mlflow.log_param(param_name, param_value)\n",
    "\n",
    "        # 3. Log metrics\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "        # 4. Set a tag for better tracking\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}-Baseline\")\n",
    "\n",
    "        print(f\"‚úÖ {model_name} logged successfully to DagsHub MLflow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d57cba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Linear_Regression logged successfully to DagsHub MLflow.\n",
      "üèÉ View run Linear_Regression-Baseline at: https://dagshub.com/vamsisaigarapati/bitcoin_price_pred_CSE574.mlflow/#/experiments/0/runs/037e6b8b0aef452aaa3aa036abb087c9\n",
      "üß™ View experiment at: https://dagshub.com/vamsisaigarapati/bitcoin_price_pred_CSE574.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "log_experiment(\n",
    "    model_name=\"Linear_Regression\",\n",
    "    params=params,\n",
    "    metrics=metrics\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bit_pred_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
